{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"idal-logo.png\" align=\"right\" style=\"float\" width=\"400\">\n",
    "<font color=\"#CA3532\"><h1 align=\"left\">mIA3</h1></font>\n",
    "<font color=\"#6E6E6E\"><h2 align=\"left\">Tarea Evaluable. Aprendizaje Profundo 1 y 2 (Parte 2 de 3).</h2></font> \n",
    "\n",
    "#### Elaborado por Felipe Ramírez Herrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import dl_common as mc\n",
    "import dl_gcnn_models as mg\n",
    "import dl_tfmr_models as mt\n",
    "import dl_xxxx_models as mm\n",
    "import dl_greedy_search as mgs\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f388410d7d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  8 10:54:04 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.43.02              Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060        On  | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   49C    P8              18W / 170W |   1107MiB / 12288MiB |     12%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torchtext.data\n",
    "import torchtext.data.datasets_utils\n",
    "import torchtext.datasets\n",
    "\n",
    "\n",
    "if os.path.exists(mc.en_vocab_file):\n",
    "    mc.en_vocabulary = torch.load(mc.en_vocab_file)\n",
    "else:\n",
    "    raise Exception(\"\")\n",
    "\n",
    "if os.path.exists(mc.es_vocab_file):\n",
    "    mc.es_vocabulary = torch.load(mc.es_vocab_file)\n",
    "else:\n",
    "    raise Exception(\"\")\n",
    "\n",
    "if os.path.exists(mc.fr_vocab_file):\n",
    "    mc.fr_vocabulary = torch.load(mc.fr_vocab_file)\n",
    "else:\n",
    "    raise Exception(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN Vocabulary Size = 74563\n",
      "ES Vocabulary Size = 91234\n",
      "FR Vocabulary Size = 86462\n"
     ]
    }
   ],
   "source": [
    "print(\"EN Vocabulary Size = {0}\".format(len(mc.en_vocabulary)))\n",
    "print(\"ES Vocabulary Size = {0}\".format(len(mc.es_vocabulary)))\n",
    "print(\"FR Vocabulary Size = {0}\".format(len(mc.fr_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.PAD_EN_IDX = mc.en_vocabulary[mc.PAD_WORD]\n",
    "mc.BOS_EN_IDX = mc.en_vocabulary[mc.BOS_WORD]\n",
    "mc.EOS_EN_IDX = mc.en_vocabulary[mc.EOS_WORD]\n",
    "mc.UNK_EN_IDX = mc.en_vocabulary[mc.UNK_WORD]\n",
    "\n",
    "\n",
    "mc.PAD_ES_IDX = mc.es_vocabulary[mc.PAD_WORD]\n",
    "mc.BOS_ES_IDX = mc.es_vocabulary[mc.BOS_WORD]\n",
    "mc.EOS_ES_IDX = mc.es_vocabulary[mc.EOS_WORD]\n",
    "mc.UNK_ES_IDX = mc.es_vocabulary[mc.UNK_WORD]\n",
    "\n",
    "mc.PAD_FR_IDX = mc.fr_vocabulary[mc.PAD_WORD]\n",
    "mc.BOS_FR_IDX = mc.fr_vocabulary[mc.BOS_WORD]\n",
    "mc.EOS_FR_IDX = mc.fr_vocabulary[mc.EOS_WORD]\n",
    "mc.UNK_FR_IDX = mc.fr_vocabulary[mc.UNK_WORD]\n",
    "\n",
    "mc.en_vocab_size = len(mc.en_vocabulary)\n",
    "mc.es_vocab_size = len(mc.es_vocabulary)\n",
    "mc.fr_vocab_size = len(mc.fr_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Records: 440944\n",
      "MAX SEQ LEN 102\n",
      "MIN SEQ LEN 7\n",
      "Training tuples: 308660 Validation tuples: 88630 Testing tuples: 43654\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from collections import Counter \n",
    "\n",
    "\n",
    "max_len = 0\n",
    "min_len = 4500\n",
    "\n",
    "fe = os.path.exists(mc.full_data_file)\n",
    "te = os.path.exists(mc.trn_data_file)\n",
    "ve = os.path.exists(mc.val_data_file)\n",
    "tt = os.path.exists(mc.tst_data_file)\n",
    "\n",
    "if fe and te and ve and tt:\n",
    "    with open(mc.full_data_file, 'rb') as fp:\n",
    "            mc.full_data = pickle.load(fp)\n",
    "    with open(mc.trn_data_file, 'rb') as fp:\n",
    "            mc.trn_subset = pickle.load(fp)\n",
    "    with open(mc.val_data_file, 'rb') as fp:\n",
    "            mc.val_subset = pickle.load(fp)        \n",
    "    with open(mc.tst_data_file, 'rb') as fp:\n",
    "            mc.tst_subset = pickle.load(fp)           \n",
    "    for (en_seq,es_seq,fr_seq) in mc.full_data:     \n",
    "        a = len(en_seq)\n",
    "        b = len(es_seq)\n",
    "        c = len(fr_seq) \n",
    "        max_len = max(max_len, a, b, c)    \n",
    "        min_len = min(min_len, a, b, c)    \n",
    "else:\n",
    "    raise Exception(\"\")\n",
    "\n",
    "if (mc.max_seq_length < max_len):\n",
    "    mc.max_seq_length = max_len + 2\n",
    "\n",
    "if (mc.min_seq_length > min_len):\n",
    "    mc.min_seq_length = min_len + 2\n",
    "\n",
    "\n",
    "print(\"Selected Records: {0}\".format(len(mc.full_data)))\n",
    "print(\"MAX SEQ LEN {0}\".format(mc.max_seq_length))\n",
    "print(\"MIN SEQ LEN {0}\".format(mc.min_seq_length))\n",
    "\n",
    "size_of_trn_set_size = len(mc.trn_subset)\n",
    "size_of_val_set_size = len(mc.val_subset)\n",
    "size_of_tst_set_size = len(mc.tst_subset)\n",
    "\n",
    "print(\"Training tuples: {0} Validation tuples: {1} Testing tuples: {2}\".format(size_of_trn_set_size, size_of_val_set_size, size_of_tst_set_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import dl_common_processing as mp\n",
    "import math\n",
    "Bilingual_EN_to_ES_tstset = DataLoader(mp.LanguageDataset(mc.tst_subset, size_of_tst_set_size), batch_size=mc.BATCH_SIZE, shuffle=False, collate_fn=mp.generate_batch_EN_ES)\n",
    "Bilingual_EN_to_FR_tstset = DataLoader(mp.LanguageDataset(mc.tst_subset, size_of_tst_set_size), batch_size=mc.BATCH_SIZE, shuffle=False, collate_fn=mp.generate_batch_EN_FR)\n",
    "Trilingual_tstset = DataLoader(mp.LanguageDataset(mc.tst_subset, size_of_tst_set_size), batch_size=mc.BATCH_SIZE, shuffle=False, collate_fn=mp.generate_batch)\n",
    "\n",
    "batches_for_testing = math.ceil( size_of_tst_set_size / mc.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcionalidad compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_metrics = []\n",
    "dt_metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/framirez/miniconda3/envs/DL_Env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "base_EN_ES_model_path = 'tfmr_single_en_es_{0}.pt'\n",
    "base_EN_FR_model_path = 'tfmr_single_en_fr_{0}.pt'\n",
    "dual_model_path = 'tfmr_dual_en_es_fr_{0}.pt'\n",
    "dual_model_path_WS = 'tfmr_dual_en_es_fr_weight_sharing_{0}.pt'\n",
    "\n",
    "transformer_base_EN_to_ES = mt.Seq2SeqTransformer(\"TFMR_EN_ES\", NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, mc.en_vocab_size, mc.es_vocab_size, FFN_HID_DIM)\n",
    "transformer_base_EN_to_FR = mt.Seq2SeqTransformer(\"TFMR_EN_FR\",NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, mc.en_vocab_size, mc.fr_vocab_size, FFN_HID_DIM)\n",
    "transformer_dual_EN_to_ES_and_FS = mt.DoubleTaskSeq2SeqTransformer(\"TFMR_DUAL_EN_ES_FR\", NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, mc.en_vocab_size, mc.es_vocab_size, mc.fr_vocab_size, FFN_HID_DIM)\n",
    "transformer_dual_EN_to_ES_and_FS_with_WS = mt.DoubleTaskSeq2SeqTransformer(\"TFMR_DUAL_EN_ES_FR (WS)\", NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, mc.en_vocab_size, mc.es_vocab_size, mc.fr_vocab_size, FFN_HID_DIM, weight_sharing=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=256, out_features=91234, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(74563, 256)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(91234, 256)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_base_EN_to_ES.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=256, out_features=86462, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(74563, 256)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(86462, 256)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_base_EN_to_FR.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoubleTaskSeq2SeqTransformer(\n",
       "  (transformer): CustomDoubleDecoderTransformer(\n",
       "    (encoder): CustomTransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x CustomTransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder_a): CustomTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x CustomTransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder_b): CustomTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x CustomTransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator_a): Linear(in_features=256, out_features=91234, bias=True)\n",
       "  (generator_b): Linear(in_features=256, out_features=86462, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(74563, 256)\n",
       "  )\n",
       "  (tgt_a_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(91234, 256)\n",
       "  )\n",
       "  (tgt_b_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(86462, 256)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_dual_EN_to_ES_and_FS.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoubleTaskSeq2SeqTransformer(\n",
       "  (transformer): CustomDoubleDecoderTransformer(\n",
       "    (encoder): CustomTransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x CustomTransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder_a): CustomTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x CustomTransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder_b): CustomTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x CustomTransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator_a): Linear(in_features=256, out_features=91234, bias=True)\n",
       "  (generator_b): Linear(in_features=256, out_features=86462, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(74563, 256)\n",
       "  )\n",
       "  (tgt_a_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(91234, 256)\n",
       "  )\n",
       "  (tgt_b_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(86462, 256)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_dual_EN_to_ES_and_FS_with_WS.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from(model, filename):\n",
    "    checkpoint = torch.load(filename.format(mc.NUMBER_OF_EPOCHS - 1))\n",
    "    if (checkpoint['epoch'] == mc.NUMBER_OF_EPOCHS - 1):\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        raise RuntimeError(\"Checkpoint {0} is corrupt\".format(mc.NUMBER_OF_EPOCHS -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el último model cargado\n",
    "\n",
    "\n",
    "load_model_from(transformer_base_EN_to_ES,  base_EN_ES_model_path)\n",
    "load_model_from(transformer_base_EN_to_FR,  base_EN_FR_model_path)\n",
    "load_model_from(transformer_dual_EN_to_ES_and_FS,  dual_model_path)\n",
    "load_model_from(transformer_dual_EN_to_ES_and_FS_with_WS,  dual_model_path_WS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = [transformer_base_EN_to_ES, transformer_base_EN_to_FR]\n",
    "\n",
    "src_langs = [mc.Language.EN, mc.Language.EN]\n",
    "tgt_langs = [mc.Language.ES, mc.Language.FR]\n",
    "\n",
    "hist = mgs.run_tfrmr_st_inference(mc.tst_subset, models, src_langs, tgt_langs)\n",
    "\n",
    "st_metrics.append(pd.DataFrame.from_dict(hist, orient='index'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = mgs.run_tfrmr_dt_inference(mc.tst_subset, [transformer_dual_EN_to_ES_and_FS, transformer_dual_EN_to_ES_and_FS_with_WS])\n",
    "\n",
    "dt_metrics.append(pd.DataFrame.from_dict(hist, orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ES_VOCAB_DIM = mc.en_vocab_size\n",
    "OUTPUT_ES_VOCAB_DIM = mc.es_vocab_size\n",
    "OUTPUT_FR_VOCAB_DIM = mc.fr_vocab_size\n",
    "GCNN_EMBDIM = 256\n",
    "GCNN_HID_DIM = 512 # each conv. layer has 2 * hid_dim filters\n",
    "GCNN_ENC_LAYERS = 5 # number of conv. blocks in encoder\n",
    "GCNN_DEC_LAYERS = 5 # number of conv. blocks in decoder\n",
    "GCNN_ENC_KERNEL_SIZE = 3 # must be odd!\n",
    "GCNN_DEC_KERNEL_SIZE = 3 # can be even or odd\n",
    "GCNN_ENC_DROPOUT = 0.25\n",
    "GCNN_DEC_DROPOUT = 0.25\n",
    "\n",
    "CNN_TRG_PAD_IDX = mc.PAD_ES_IDX\n",
    "\n",
    "CNN_EN_ES_model_path = 'gcnn_mt_en_es_{0}.pt'\n",
    "CNN_EN_FR_model_path = 'gcnn_mt__en_fr_{0}.pt'\n",
    "CNN_EN_ES_FR_model_path = 'gcnn_mt_en_es_fr_{0}.pt'\n",
    "CNN_EN_ES_FR_WS_model_path = 'gcnn_mt_ws_en_es_fr_{0}.pt'\n",
    "\n",
    "CNN_ES_enc = mg.GatedConvEncoder(INPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_ENC_LAYERS, GCNN_ENC_KERNEL_SIZE, GCNN_ENC_DROPOUT, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_ES_dec = mg.GatedConvDecoder(OUTPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_DEC_LAYERS, GCNN_DEC_KERNEL_SIZE, GCNN_DEC_DROPOUT, CNN_TRG_PAD_IDX, mm.DEVICE, mc.max_seq_length)\n",
    "\n",
    "CNN_FR_enc = mg.GatedConvEncoder(INPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_ENC_LAYERS, GCNN_ENC_KERNEL_SIZE, GCNN_ENC_DROPOUT, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_FR_dec = mg.GatedConvDecoder(OUTPUT_FR_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_DEC_LAYERS, GCNN_DEC_KERNEL_SIZE, GCNN_DEC_DROPOUT, CNN_TRG_PAD_IDX, mm.DEVICE, mc.max_seq_length)\n",
    "\n",
    "CNN_model_EN_ES = mg.GatedConvSeq2Seq(\"CNN_EN_ES\", CNN_ES_enc, CNN_ES_dec)\n",
    "CNN_model_EN_FR = mg.GatedConvSeq2Seq(\"CNN_EN_FR\", CNN_FR_enc, CNN_FR_dec)\n",
    "\n",
    "CNN_DUAL_enc = mg.GatedConvEncoder(INPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_ENC_LAYERS, GCNN_ENC_KERNEL_SIZE, GCNN_ENC_DROPOUT, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_DUAL_ES_dec = mg.GatedConvDecoder(OUTPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_DEC_LAYERS, GCNN_DEC_KERNEL_SIZE, GCNN_DEC_DROPOUT, CNN_TRG_PAD_IDX, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_DUAL_FR_dec = mg.GatedConvDecoder(OUTPUT_FR_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_DEC_LAYERS, GCNN_DEC_KERNEL_SIZE, GCNN_DEC_DROPOUT, CNN_TRG_PAD_IDX, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_DUAL_model = mg.GatedConvDualTaskSeq2Seq(\"CNN_EN_ES_FR\", CNN_DUAL_enc, CNN_DUAL_ES_dec, CNN_DUAL_FR_dec)\n",
    "\n",
    "CNN_DUAL_WS_enc = mg.GatedConvEncoder(INPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_ENC_LAYERS, GCNN_ENC_KERNEL_SIZE, GCNN_ENC_DROPOUT, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_DUAL_WS_ES_dec = mg.GatedConvDecoder(OUTPUT_ES_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_DEC_LAYERS, GCNN_DEC_KERNEL_SIZE, GCNN_DEC_DROPOUT, CNN_TRG_PAD_IDX, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_DUAL_WS_FR_dec = mg.GatedConvDecoder(OUTPUT_FR_VOCAB_DIM, GCNN_EMBDIM, GCNN_HID_DIM, GCNN_DEC_LAYERS, GCNN_DEC_KERNEL_SIZE, GCNN_DEC_DROPOUT, CNN_TRG_PAD_IDX, mm.DEVICE, mc.max_seq_length)\n",
    "CNN_DUAL_WS_model = mg.GatedConvDualTaskSeq2Seq(\"CNN_EN_ES_FR (WS)\", CNN_DUAL_WS_enc, CNN_DUAL_WS_ES_dec, CNN_DUAL_WS_FR_dec, shared_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_from(CNN_model_EN_ES,  CNN_EN_ES_model_path)\n",
    "load_model_from(CNN_model_EN_FR,  CNN_EN_FR_model_path)\n",
    "load_model_from(CNN_DUAL_model,  CNN_EN_ES_FR_model_path)\n",
    "load_model_from(CNN_DUAL_WS_model,  CNN_EN_ES_FR_WS_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedConvSeq2Seq(\n",
       "  (encoder): GatedConvEncoder(\n",
       "    (tok_embedding): Embedding(74563, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (decoder): GatedConvDecoder(\n",
       "    (tok_embedding): Embedding(91234, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (dec_incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dec_outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_incoming_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_outgoing_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=256, out_features=91234, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model_EN_ES.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedConvSeq2Seq(\n",
       "  (encoder): GatedConvEncoder(\n",
       "    (tok_embedding): Embedding(74563, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (decoder): GatedConvDecoder(\n",
       "    (tok_embedding): Embedding(86462, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (dec_incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dec_outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_incoming_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_outgoing_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=256, out_features=86462, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model_EN_FR.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedConvDualTaskSeq2Seq(\n",
       "  (encoder): GatedConvEncoder(\n",
       "    (tok_embedding): Embedding(74563, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (decoder_a): GatedConvDecoder(\n",
       "    (tok_embedding): Embedding(91234, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (dec_incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dec_outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_incoming_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_outgoing_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=256, out_features=91234, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (decoder_b): GatedConvDecoder(\n",
       "    (tok_embedding): Embedding(86462, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (dec_incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dec_outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_incoming_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_outgoing_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=256, out_features=86462, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_DUAL_model.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedConvDualTaskSeq2Seq(\n",
       "  (encoder): GatedConvEncoder(\n",
       "    (tok_embedding): Embedding(74563, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (decoder_a): GatedConvDecoder(\n",
       "    (tok_embedding): Embedding(91234, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (dec_incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dec_outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_incoming_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_outgoing_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=256, out_features=91234, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (decoder_b): GatedConvDecoder(\n",
       "    (tok_embedding): Embedding(86462, 256)\n",
       "    (pos_embedding): Embedding(102, 256)\n",
       "    (dec_incoming_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dec_outgoing_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_incoming_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (attn_outgoing_projection): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=256, out_features=86462, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-4): 5 x Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_DUAL_WS_model.to(mm.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CNN_EN_ES\n",
      "1.SRC_SEQ:   in its submissions of   february and   june   the state party contests any violations of the covenant\n",
      "1.TGT_SEQ:   en sus exposiciones de   de febrero y   de junio de   el estado parte impugna que se haya violado el pacto\n",
      "1.OUT_SEQ:  en sus observaciones de   de febrero y   de junio de   el estado parte se refiere a las violaciones de\n",
      "2.SRC_SEQ:   targetgroup stations these are aimed at a specific target group within the flemish community\n",
      "2.TGT_SEQ:   las emisoras destinadas a grupos concretos estan dirigidas a un grupo particular en la comunidad flamenca\n",
      "2.OUT_SEQ:  las estaciones de alta comercio se trata de un grupo especifico de objetivo en la que se\n",
      "3.SRC_SEQ: we consider it a promising sign that support has been coming from member states belonging to various groups\n",
      "3.TGT_SEQ: consideramos que esa propuesta es un signo prometedor del apoyo que vienen prestando los estados miembros pertenecientes a diversos grupos\n",
      "3.OUT_SEQ:  considerando que se ha senalado un apoyo de los estados miembros pertenecientes a los estados miembros pertenecientes a los estados\n",
      "4.SRC_SEQ: a number of the above activities are ongoing and funded under the current budget and additional activities come within the approval to extend the current programme for which funding is being sought\n",
      "4.TGT_SEQ: algunas de las actividades mencionadas se estan llevando a cabo y se financian con arreglo al presupuesto actual y las actividades adicionales dependen de que se apruebe la extension del programa vigente para lo cual se estan buscando fondos\n",
      "4.OUT_SEQ:  numero de las actividades mencionadas se estan tratando de la preparacion y de fondos adicionales en el presupuesto actual y las actividades adicionales que se estan haciendo en la aprobacion de la aprobacion de\n",
      "5.SRC_SEQ: finally the passage of the nationality law means that the immigration law concerns about which were raised by the secretarygeneral will now come into effect\n",
      "5.TGT_SEQ: por ultimo la aprobacion de la ley sobre nacionalidad tiene por consecuencia la entrada en vigor de la ley sobre inmigracion respecto de la cual el secretario general ha planteado ya su preocupacion\n",
      "5.OUT_SEQ:  el establecimiento de la ley de nacionalidad se entiende que la ley de inmigracion se refiere a las cuales se le ha planteado el secretario general esta\n",
      "6.SRC_SEQ: acl   draft resolution entitled objective information on military matters including transparency of military expenditures submitted on   october   by argentina australia austria belgium bulgaria canada chile costa rica croatia denmark ecuador estonia finland france germany greece guatemala hungary ireland israel italy japan latvia lithuania luxembourg malta netherlands new zealand norway poland portugal republic of moldova romania slovakia slovenia spain sweden the former yugoslav republic of macedonia ukraine and united states of america\n",
      "6.TGT_SEQ: acl   proyecto de resolucion titulado informacion objetiva sobre cuestiones militares incluida la transparencia de los gastos militares presentado el   de octubre de   por alemania argentina australia austria belgica bulgaria canada chile costa rica croacia dinamarca ecuador eslovaquia eslovenia espana estados unidos de america estonia ex republica yugoslava de macedonia finlandia francia grecia guatemala hungria irlanda israel italia japon letonia lituania luxemburgo malta noruega nueva zelandia paises bajos polonia portugal republica de moldova rumania suecia y ucrania\n",
      "6.OUT_SEQ:    proyecto de resolucion titulado informacion objetiva sobre cuestiones militares incluidas la transparencia de los gastos militares presentados el   de octubre de   por la argentina australia austria belgica bulgaria canada chile costa rica croacia dinamarca ecuador estonia finlandia francia grecia guatemala hungria irlanda italia japon letonia lituania luxemburgo malta malta noruega noruega malta luxemburgo malta luxemburgo malta luxemburgo malta noruega noruega nueva zelandia polonia portugal republica de moldova rumania republica yugoslava de macedonia republica\n",
      "7.SRC_SEQ: these aspects will be of particular concern to the host government in respect of infrastructure facilities open to use by the general public such as a bridge or tunnel or of a hazardous nature such as power plants or gas distribution networks\n",
      "7.TGT_SEQ: estos aspectos interesaran especialmente al gobiernos anfitrion en el caso de obras de infraestructura abiertas al publico como un puente o un tunel o de caracter peligroso como centrales electricas o redes de conduccion de gas\n",
      "7.OUT_SEQ:  los aspectos seran de particular preocupacion al gobierno anfitrion en relacion con las instalaciones de infraestructura que se le han podido utilizar por el publico general como un puente o el grado tan peligroso como las plantas de energia o las plantas de productos\n",
      "8.SRC_SEQ: it is one of the elements of the state social policy and as such constitutes part of the social security system\n",
      "8.TGT_SEQ: es uno de los elementos de la politica social del estado y como tal constituye parte del sistema de seguridad social\n",
      "8.OUT_SEQ:  es uno de los elementos del orden social del estado y como como la forma parte del sistema social social y como como\n",
      "9.SRC_SEQ: advertisements were placed in publications for young people and television spots were broadcast against xenophobia with a view among other things to encouraging young people to behave fairly towards foreigners and show them some understanding\n",
      "9.TGT_SEQ: se publicaron anuncios en las revistas de jovenes y se difundieron por television cortos contra la xenofobia a fin de que los jovenes tuvieran un comportamiento justo con los extranjeros y les dieran muestras de comprension\n",
      "9.OUT_SEQ:  se formularon en publicaciones para los jovenes y los lugares de television se recibieron en las publicaciones para los jovenes y se han hecho en la actualidad entre otras cosas para alentar a los jovenes a que\n",
      "10.SRC_SEQ:   for the remainder of   seminars and legalassistance briefing missions are being planned in africa asia latin america and eastern europe\n",
      "10.TGT_SEQ:   para el resto de   se han previsto seminarios y misiones de informacion sobre asistencia juridica en africa america latina asia el caribe y europa oriental\n",
      "10.OUT_SEQ:  para el resto de   seminarios y misiones de informacion sobre el terreno se esta previsto en la region de africa asia america latina\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 3 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m src_langs \u001b[38;5;241m=\u001b[39m [mc\u001b[38;5;241m.\u001b[39mLanguage\u001b[38;5;241m.\u001b[39mEN, mc\u001b[38;5;241m.\u001b[39mLanguage\u001b[38;5;241m.\u001b[39mEN]\n\u001b[1;32m      8\u001b[0m tgt_langs \u001b[38;5;241m=\u001b[39m [mc\u001b[38;5;241m.\u001b[39mLanguage\u001b[38;5;241m.\u001b[39mES, mc\u001b[38;5;241m.\u001b[39mLanguage\u001b[38;5;241m.\u001b[39mFR]\n\u001b[0;32m---> 10\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_gccn_st_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtst_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_langs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_langs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m st_metrics\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(hist, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/dl_greedy_search.py:554\u001b[0m, in \u001b[0;36mrun_gccn_st_inference\u001b[0;34m(tst_subset, tst_models, tst_slangs, tst_tlangs, threshold)\u001b[0m\n\u001b[1;32m    552\u001b[0m         now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    553\u001b[0m         time_str \u001b[38;5;241m=\u001b[39m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 554\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m [\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m{1}\u001b[39;49;00m\u001b[38;5;124;43m] - inference - \u001b[39;49m\u001b[38;5;132;43;01m{2}\u001b[39;49;00m\u001b[38;5;124;43m BLEU: \u001b[39;49m\u001b[38;5;132;43;01m{3}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetName\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_blue_score\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    556\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    558\u001b[0m inference_avg_time \u001b[38;5;241m=\u001b[39m inference_ttl_time \u001b[38;5;241m/\u001b[39m i\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 3 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "# Inferencia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = [CNN_model_EN_ES, CNN_model_EN_FR]\n",
    "\n",
    "src_langs = [mc.Language.EN, mc.Language.EN]\n",
    "tgt_langs = [mc.Language.ES, mc.Language.FR]\n",
    "\n",
    "hist = mgs.run_gccn_st_inference(mc.tst_subset, models, src_langs, tgt_langs)\n",
    "\n",
    "st_metrics.append(pd.DataFrame.from_dict(hist, orient='index'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = mgs.run_gccn_dt_inference(mc.tst_subset, [CNN_DUAL_model, CNN_DUAL_WS_model])\n",
    "\n",
    "dt_metrics.append(pd.DataFrame.from_dict(hist, orient='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_st = pd.concat(st_metrics)\n",
    "results_for_st.to_csv(\"./st_inference.csv\", sep=';', index=True, encoding='utf-8')\n",
    "\n",
    "print(results_for_st)\n",
    "\n",
    "results_for_dt = pd.concat(dt_metrics)\n",
    "results_for_dt.to_csv(\"./dt_inference.csv\", sep=';', index=True, encoding='utf-8')\n",
    "\n",
    "print(results_for_dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
