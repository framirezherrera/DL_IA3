{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"idal-logo.png\" align=\"right\" style=\"float\" width=\"400\">\n",
    "<font color=\"#CA3532\"><h1 align=\"left\">mIA3</h1></font>\n",
    "<font color=\"#6E6E6E\"><h2 align=\"left\">Tarea Evaluable. Aprendizaje Profundo 1 y 2 (Parte 3 de 3).</h2></font> \n",
    "\n",
    "#### Elaborado por Felipe Ramírez Herrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install panda\n",
    "\n",
    "# !pip install torch\n",
    "# !pip install torchtext\n",
    "# !pip install torchmetrics\n",
    "# !pip install spacy\n",
    "\n",
    "# !pip install jupyter\n",
    "# !pip install ipywidgets\n",
    "\n",
    "# !pip install editdistance\n",
    "# !pip install six\n",
    "# !pip install typeguard\n",
    "\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download es_core_news_sm\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !pip install wget\n",
    "\n",
    "# !pip install --upgrade --force-reinstall torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import csv\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import Vocab\n",
    "import logging\n",
    "import pandas as pd\n",
    "import six\n",
    "from typing import List, Tuple, Union\n",
    "from argparse import Namespace\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as mp\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de Mathplotlib\n",
    "\n",
    "mp.rc('font', size=8)\n",
    "mp.rc('axes', titlesize=8)\n",
    "mp.rc('axes', labelsize=8)\n",
    "mp.rc('xtick', labelsize=8)\n",
    "mp.rc('ytick', labelsize=8)\n",
    "mp.rc('legend', fontsize=8)\n",
    "mp.rc('figure', titlesize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda_memory_available():\n",
    "    if torch.cuda.is_available():\n",
    "        t = torch.cuda.get_device_properties(DEVICE).total_memory\n",
    "        r = torch.cuda.memory_reserved(DEVICE)\n",
    "        a = torch.cuda.memory_allocated(DEVICE)\n",
    "        f = (t - a - r) / t  # free inside reserved\n",
    "        print(\"CUDA Available Memory: {0}\".format(f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model, return_int=False):\n",
    "    params = sum([torch.prod(torch.tensor(x.shape)).item() for x in model.parameters() if x.requires_grad])\n",
    "    if return_int:\n",
    "        return params\n",
    "    else:\n",
    "        print(\"There are {:,} trainable parameters in this model.\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELIMINAR\n",
    "\n",
    "# import re\n",
    "# import unicodedata\n",
    "\n",
    "# def unicodeToAscii(s):\n",
    "#     return ''.join(\n",
    "#       c for c in unicodedata.normalize('NFD', s) \n",
    "#       if unicodedata.category(c) != 'Mn'\n",
    "#     )\n",
    "\n",
    "# def normalizeString(s):\n",
    "#     s = unicodeToAscii(s.lower().strip())\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", \" \", s)\n",
    "#     return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://conferences.unite.un.org/UNCorpus/Home/DownloadOverview\n",
    "# !cat /home/framirez/translation_multilingual/UNv1.0.6way.tar.gz.* | tar -xzf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# EN_corpus_file = \"UNv1.0.6way_en.zip\" # UN Parallel Corpus English (EN)\n",
    "# ES_corpus_file = \"UNv1.0.6way_es.zip\" # UN Parallel Corpus Spanish (ES)\n",
    "# FR_corpus_file = \"UNv1.0.6way_fr.zip\" # UN Parallel Corpus French (FR)\n",
    "\n",
    "# corpus_source_folder = \"/content/drive/MyDrive/\"\n",
    "# corpus_target_folder = \"/tmp/\"\n",
    "\n",
    "# if (not os.path.exists(corpus_target_folder + EN_corpus_file)):\n",
    "#   with zipfile.ZipFile(corpus_source_folder + EN_corpus_file,\"r\") as zip_ref:\n",
    "#       zip_ref.extractall(corpus_target_folder)\n",
    "\n",
    "# if (not os.path.exists(corpus_target_folder + ES_corpus_file)):\n",
    "#   with zipfile.ZipFile(corpus_source_folder + ES_corpus_file,\"r\") as zip_ref:\n",
    "#       zip_ref.extractall(corpus_target_folder)\n",
    "\n",
    "# if (not os.path.exists(corpus_target_folder + FR_corpus_file)):\n",
    "#   with zipfile.ZipFile(corpus_source_folder + FR_corpus_file,\"r\") as zip_ref:\n",
    "#       zip_ref.extractall(corpus_target_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cuDNN backend for 16-bit training and inference for CUDA-enabled GPUs\n",
    "# torch.backends.cudnn.benchmark =  True\n",
    "# torch.backends.cudnn.enabled =  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 64 # Re-calculated further \n",
    "min_seq_length = 16 # Re-calculated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUMBER_OF_EPOCHS = 1\n",
    "EARLY_STOPPING_EPOCHS = 3\n",
    "CLIPPING_VALUE = 15                   # clipping value, or None to prevent gradient clipping\n",
    "MAXIMUM_NUMBER_OF_SAMPLES = 500000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Lets GPU to get more cooler\n",
    "INNER_GPU_REST_TIME = 0 # Rest time between epochs\n",
    "OUTER_GPU_REST_TIME = 0 # Rest time between model training / validation processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "def generate_examples(src_file, tgt_a_file, tgt_b_file):\n",
    "    data = []\n",
    "    with open(src_file, encoding=\"utf-8\") as src_f, open(tgt_a_file, encoding=\"utf-8\") as tgt_a, open(tgt_b_file, encoding=\"utf-8\") as tgt_b:\n",
    "        for idx, (a, b, c) in enumerate(zip(src_f, tgt_a, tgt_b)):           \n",
    "            if (a.isspace() | b.isspace() | c.isspace()):\n",
    "                continue\n",
    "            data.append({'text_en' : a, 'text_es' : b, 'text_fr' :c} )\n",
    "    return pd.DataFrame.from_records(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "PAD_WORD = '<pad>'\n",
    "UNK_WORD = '<unk>'  # Unknown token symbol\n",
    "BOS_WORD = '<bos>'  # Begin-of-Sentence token symbol\n",
    "EOS_WORD = '<eos>'  # End-of-Sentence token symbol\n",
    "\n",
    "def clean_text(text : str):\n",
    "    text = normalize('NFD', str(text).lower())\n",
    "    text = re.sub('[^A-Za-z ]+', '', text)\n",
    "    return text\n",
    "\n",
    "pkl_dataset_file = \"transformers_us_ds.pkl\"\n",
    "un_ds = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(pkl_dataset_file):\n",
    "    un_ds = pd.read_pickle(pkl_dataset_file) \n",
    "else:\n",
    "    en_train_path = \"./mnt/drive/UNv1.0.6way.en\"\n",
    "    es_train_path = \"./mnt/drive/UNv1.0.6way.es\"\n",
    "    fr_train_path = \"./mnt/drive/UNv1.0.6way.fr\"\n",
    "    df = generate_examples(en_train_path, es_train_path, fr_train_path)\n",
    "    df['text_en'] = df['text_en'].apply(lambda row: clean_text(row))\n",
    "    df['text_es'] = df['text_es'].apply(lambda row: clean_text(row))\n",
    "    df['text_fr'] = df['text_fr'].apply(lambda row: clean_text(row))\n",
    "    un_ds = df\n",
    "    un_ds.to_pickle(pkl_dataset_file)\n",
    "len(un_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_ds.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_ds.head(-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_ds = un_ds.head(MAXIMUM_NUMBER_OF_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import torchtext\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "es_tokenizer = get_tokenizer('spacy', language='es_core_news_sm')\n",
    "fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
    "\n",
    "Language = Enum('Language', ['EN', 'ES', 'FR'])\n",
    "\n",
    "def yield_tokens(Lang: Language=Language.EN):\n",
    "    for index, row in un_ds.iterrows():     \n",
    "         if (Lang == Language.EN):\n",
    "            yield en_tokenizer(str(row[\"text_en\"]))  \n",
    "         if (Lang == Language.ES):\n",
    "            yield es_tokenizer(str(row[\"text_es\"]))\n",
    "         if (Lang == Language.FR):\n",
    "           yield fr_tokenizer(str(row[\"text_fr\"]))\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab_file = 'transformers_vocab_en.pth'\n",
    "es_vocab_file = 'transformers_vocab_es.pth'\n",
    "fr_vocab_file = 'transformers_vocab_fr.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torchtext.data\n",
    "import torchtext.data.datasets_utils\n",
    "import torchtext.datasets\n",
    "\n",
    "SPECIALS = [PAD_WORD, BOS_WORD, EOS_WORD,  UNK_WORD]\n",
    "\n",
    "en_vocabulary = None\n",
    "es_vocabulary = None\n",
    "fr_vocabulary = None\n",
    "\n",
    "if os.path.exists(en_vocab_file):\n",
    "    en_vocabulary = torch.load(en_vocab_file)\n",
    "else:\n",
    "    en_vocabulary = build_vocab_from_iterator(yield_tokens(Language.EN), specials=SPECIALS)\n",
    "    torch.save(en_vocabulary, en_vocab_file)\n",
    "\n",
    "if os.path.exists(es_vocab_file):\n",
    "    es_vocabulary = torch.load(es_vocab_file)\n",
    "else:\n",
    "    es_vocabulary = build_vocab_from_iterator(yield_tokens(Language.ES), specials=SPECIALS)\n",
    "    torch.save(es_vocabulary, es_vocab_file)\n",
    "\n",
    "if os.path.exists(fr_vocab_file):\n",
    "    fr_vocabulary = torch.load(fr_vocab_file)\n",
    "else:\n",
    "    fr_vocabulary = build_vocab_from_iterator(yield_tokens(Language.FR), specials=SPECIALS)\n",
    "    torch.save(fr_vocabulary, fr_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EN Vocabulary Size = {0}\", len(en_vocabulary))\n",
    "print(\"ES Vocabulary Size = {0}\", len(es_vocabulary))\n",
    "print(\"FR Vocabulary Size = {0}\", len(fr_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_EN_IDX = en_vocabulary[PAD_WORD]\n",
    "BOS_EN_IDX = en_vocabulary[BOS_WORD]\n",
    "EOS_EN_IDX = en_vocabulary[EOS_WORD]\n",
    "UNK_EN_IDX = en_vocabulary[UNK_WORD]\n",
    "\n",
    "\n",
    "PAD_ES_IDX = es_vocabulary[PAD_WORD]\n",
    "BOS_ES_IDX = es_vocabulary[BOS_WORD]\n",
    "EOS_ES_IDX = es_vocabulary[EOS_WORD]\n",
    "UNK_ES_IDX = es_vocabulary[UNK_WORD]\n",
    "\n",
    "PAD_FR_IDX = fr_vocabulary[PAD_WORD]\n",
    "BOS_FR_IDX = fr_vocabulary[BOS_WORD]\n",
    "EOS_FR_IDX = fr_vocabulary[EOS_WORD]\n",
    "UNK_FR_IDX = fr_vocabulary[UNK_WORD]\n",
    "\n",
    "en_vocab_size = len(en_vocabulary) + 1\n",
    "es_vocab_size = len(es_vocabulary) + 1\n",
    "fr_vocab_size = len(fr_vocabulary) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(tokenized_text, allocate : bool = True,  pad_index : int = PAD_EN_IDX, bos_index : int = BOS_EN_IDX, eos_index : int = EOS_EN_IDX):  \n",
    "    result = []\n",
    "    if len(tokenized_text) < max_seq_length:\n",
    "        if (allocate):\n",
    "            result = [bos_index] + tokenized_text + [eos_index]\n",
    "            left = max_seq_length - len(result)\n",
    "            padding = [pad_index] * left\n",
    "            result = result + padding\n",
    "        else:\n",
    "            left = max_seq_length - len(tokenized_text)\n",
    "            padding = [pad_index] * left\n",
    "            result = tokenized_text + padding       \n",
    "    else:\n",
    "        raise Exception(\"pad_or_truncate: max_seq_length not computed properly\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_file = 'transformers_full.pth'\n",
    "trn_data_file = 'transformers_trn.pth'\n",
    "val_data_file = 'transformers_val.pth'\n",
    "tst_data_file = 'transformers_tst.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(un_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from collections import Counter \n",
    "\n",
    "MINIMUM_ALLOWED_SIZE_OF_SEQ = 5\n",
    "MAXIMUM_ALLOWED_SIZE_OF_SEQ = 100\n",
    "\n",
    "full_data = []\n",
    "trn_subset, val_subset, tst_subset = [], [], []\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "max_len = 0\n",
    "min_len = 4500\n",
    "\n",
    "en_counter = Counter()\n",
    "es_counter = Counter()\n",
    "fr_counter = Counter()\n",
    "\n",
    "en_lengths = []\n",
    "es_lengths = []\n",
    "fr_lengths = []\n",
    "\n",
    "fe = os.path.exists(full_data_file)\n",
    "te = os.path.exists(trn_data_file)\n",
    "ve = os.path.exists(val_data_file)\n",
    "tt = os.path.exists(tst_data_file)\n",
    "\n",
    "if fe and te and ve and tt:\n",
    "    with open(full_data_file, 'rb') as fp:\n",
    "            full_data = pickle.load(fp)\n",
    "    with open(trn_data_file, 'rb') as fp:\n",
    "            trn_subset = pickle.load(fp)\n",
    "    with open(val_data_file, 'rb') as fp:\n",
    "            val_subset = pickle.load(fp)        \n",
    "    with open(tst_data_file, 'rb') as fp:\n",
    "            tst_subset = pickle.load(fp)           \n",
    "    for (en_seq,es_seq,fr_seq) in full_data:     \n",
    "        en_counter.update(en_seq)\n",
    "        es_counter.update(es_seq)\n",
    "        fr_counter.update(fr_seq)\n",
    "        a = len(en_seq)\n",
    "        b = len(es_seq)\n",
    "        c = len(fr_seq) \n",
    "        en_lengths.append(a)\n",
    "        es_lengths.append(b)\n",
    "        fr_lengths.append(c)\n",
    "        max_len = max(max_len, a, b, c)    \n",
    "        min_len = min(min_len, a, b, c)    \n",
    "else:\n",
    "    for idx, row in un_ds.iterrows():\n",
    "        \n",
    "        en_exp = row[\"text_en\"].rstrip(\"\\n\")\n",
    "        es_exp = row[\"text_es\"].rstrip(\"\\n\")\n",
    "        fr_exp = row[\"text_fr\"].rstrip(\"\\n\")\n",
    "\n",
    "        en_seq = [en_vocabulary[token] for token in en_tokenizer(en_exp)]\n",
    "        es_seq = [es_vocabulary[token] for token in es_tokenizer(es_exp)]\n",
    "        fr_seq = [fr_vocabulary[token] for token in fr_tokenizer(fr_exp)]\n",
    "\n",
    "        a = len(en_seq)\n",
    "        b = len(es_seq)\n",
    "        c = len(fr_seq) \n",
    "\n",
    "        seq_min = min(a, b, c)\n",
    "        seq_max = max(a, b, c)\n",
    "\n",
    "        if seq_min  >= MINIMUM_ALLOWED_SIZE_OF_SEQ and seq_max <= MAXIMUM_ALLOWED_SIZE_OF_SEQ: \n",
    "            \n",
    "            en_counter.update(en_seq)\n",
    "            es_counter.update(es_seq)\n",
    "            fr_counter.update(fr_seq)\n",
    "       \n",
    "            en_lengths.append(a)\n",
    "            es_lengths.append(b)\n",
    "            fr_lengths.append(c)\n",
    "\n",
    "            max_len = max(max_len, seq_max)\n",
    "            min_len = min(min_len, seq_min) \n",
    "            full_data.append((en_seq, es_seq, fr_seq))\n",
    "\n",
    "    trn_subset, val_subset = train_test_split(full_data, test_size=0.3, train_size=0.7, random_state=1234, shuffle=True)\n",
    "    val_subset, tst_subset = train_test_split(val_subset, test_size=0.33, train_size=0.67, random_state=1234, shuffle=True)\n",
    "\n",
    "    with open(full_data_file, 'wb') as fp:\n",
    "        pickle.dump(full_data, fp)\n",
    "    with open(trn_data_file, 'wb') as fp:\n",
    "        pickle.dump(trn_subset, fp)\n",
    "    with open(val_data_file, 'wb') as fp:\n",
    "        pickle.dump(val_subset, fp)\n",
    "    with open(tst_data_file, 'wb') as fp:\n",
    "        pickle.dump(tst_subset, fp)\n",
    "\n",
    "if (max_seq_length < max_len):\n",
    "    max_seq_length = max_len + 2\n",
    "\n",
    "if (min_seq_length > min_len):\n",
    "    min_seq_length = min_len + 2\n",
    "\n",
    "\n",
    "print(\"Selected Records: {0}\".format(len(full_data)))\n",
    "print(\"MAX SEQ LEN {0}\".format(max_seq_length))\n",
    "print(\"MIN SEQ LEN {0}\".format(min_seq_length))\n",
    "\n",
    "size_of_trn_set_size = len(trn_subset)\n",
    "size_of_val_set_size = len(val_subset)\n",
    "size_of_tst_set_size = len(tst_subset)\n",
    "\n",
    "print(\"Training tuples: {0} Validation tuples: {1} Testing tuples: {2}\".format(size_of_trn_set_size, size_of_val_set_size, size_of_tst_set_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mp.figure(figsize=(8, 10))\n",
    "ax0 = fig.add_subplot(311)\n",
    "ax0.hist(en_lengths, rwidth=0.8, color='gray')\n",
    "ax0.set_title(\"English Sentence Length\")\n",
    "ax0.set_xlabel(\"# Tokens in Sentence\")\n",
    "\n",
    "ax1 = fig.add_subplot(312)\n",
    "ax1.hist(es_lengths, rwidth=0.8, color='gray')\n",
    "ax1.set_title(\"Spanish Sentence Length\")\n",
    "ax1.set_xlabel(\"# Tokens in Sentence\")\n",
    "\n",
    "ax2 = fig.add_subplot(313)\n",
    "ax2.hist(fr_lengths, rwidth=0.8, color='gray')\n",
    "ax2.set_title(\"French Sentence Length\")\n",
    "ax2.set_xlabel(\"# Tokens in Sentence\")\n",
    "\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.figure(figsize=(8,6))\n",
    "mp.hist2d(en_lengths, es_lengths, bins=max_seq_length-2, cmap='binary')\n",
    "mp.title(\"Joint Distribution of Sentence Lengths\")\n",
    "mp.xlabel(\"# English Tokens\")\n",
    "mp.ylabel(\"# Spanish Tokens\")\n",
    "mp.colorbar()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.figure(figsize=(8,6))\n",
    "mp.hist2d(en_lengths, fr_lengths, bins=max_seq_length-2, cmap='binary')\n",
    "mp.title(\"Joint Distribution of Sentence Lengths\")\n",
    "mp.xlabel(\"# English Tokens\")\n",
    "mp.ylabel(\"# French Tokens\")\n",
    "mp.colorbar()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(counter : Counter, vocab: Vocab, k=20, ax=None):\n",
    "    top_k = counter.most_common(k)\n",
    "    tokens, freqs = zip(*reversed(top_k))\n",
    "    \n",
    "    words = [vocab.lookup_token(token) for token in tokens]\n",
    "\n",
    "\n",
    "    if ax is None:\n",
    "        mp.barh(words, freqs, color='gray')\n",
    "    else:\n",
    "        ax.barh(words, freqs, color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = mp.figure(figsize=(14, 8))\n",
    "\n",
    "ax0 = fig.add_subplot(131)\n",
    "plot_top_words(en_counter, en_vocabulary, ax=ax0)\n",
    "ax0.set_title(\"Top 20 English Words\")\n",
    "ax0.set_xlabel(\"Raw Frequency\")\n",
    "\n",
    "ax1 = fig.add_subplot(132)\n",
    "plot_top_words(es_counter,es_vocabulary, ax=ax1)\n",
    "ax1.set_title(\"Top 20 Spanish Words\")\n",
    "ax1.set_xlabel(\"Raw Frequency\")\n",
    "\n",
    "ax2 = fig.add_subplot(133)\n",
    "plot_top_words(fr_counter,fr_vocabulary, ax=ax2)\n",
    "ax2.set_title(\"Top 20 French Words\")\n",
    "ax2.set_xlabel(\"Raw Frequency\")\n",
    "\n",
    "mp.tight_layout()\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "for en_id, es_id, fr_id in zip(en_vocabulary.lookup_indices(SPECIALS), es_vocabulary.lookup_indices(SPECIALS), fr_vocabulary.lookup_indices(SPECIALS)):\n",
    "  assert en_id == es_id & es_id == fr_id\n",
    "\n",
    "\n",
    "def tensor_transform(token_ids: List[int], bos_idx, eos_idx): # 57.1 segs\n",
    "    list = [bos_idx] + token_ids + [eos_idx]                         \n",
    "    return torch.as_tensor(list, device=DEVICE)\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    en_batch, es_batch, fr_batch = [], [], []\n",
    "    for (en_item, es_item, fr_item) in data_batch:     \n",
    "        en_t = tensor_transform(en_item, BOS_EN_IDX, EOS_EN_IDX)\n",
    "        es_t = tensor_transform(es_item, BOS_ES_IDX, EOS_ES_IDX)\n",
    "        fr_t = tensor_transform(fr_item, BOS_FR_IDX, EOS_FR_IDX)     \n",
    "        en_batch.append(en_t)\n",
    "        es_batch.append(es_t)\n",
    "        fr_batch.append(fr_t)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_EN_IDX, batch_first=False)\n",
    "    es_batch = pad_sequence(es_batch, padding_value=PAD_ES_IDX, batch_first=False)\n",
    "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_FR_IDX, batch_first=False)\n",
    "    return en_batch, es_batch, fr_batch\n",
    "\n",
    "def generate_batch_EN_ES(data_batch):\n",
    "    en_batch, es_batch = [], []\n",
    "    for (en_item, es_item, _) in data_batch:     \n",
    "        en_t = tensor_transform(en_item, BOS_EN_IDX, EOS_EN_IDX)\n",
    "        es_t = tensor_transform(es_item, BOS_ES_IDX, EOS_ES_IDX)\n",
    "        en_batch.append(en_t)\n",
    "        es_batch.append(es_t)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_EN_IDX, batch_first=False)\n",
    "    es_batch = pad_sequence(es_batch, padding_value=PAD_ES_IDX, batch_first=False)\n",
    "    return en_batch, es_batch\n",
    "\n",
    "def generate_batch_EN_FR(data_batch):\n",
    "    en_batch, fr_batch = [], []\n",
    "    for (en_item, _, fr_item) in data_batch:        \n",
    "        en_t = tensor_transform(en_item, BOS_EN_IDX, EOS_EN_IDX)\n",
    "        fr_t = tensor_transform(fr_item, BOS_FR_IDX, EOS_FR_IDX)\n",
    "        en_batch.append(en_t)\n",
    "        fr_batch.append(fr_t)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_EN_IDX, batch_first=False)\n",
    "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_ES_IDX, batch_first=False)\n",
    "    return en_batch, fr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LanguageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, subset, length):\n",
    "        self.length = length\n",
    "        self.subset = subset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.subset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Bilingual_EN_to_ES_trnset = DataLoader(LanguageDataset(trn_subset, size_of_trn_set_size), batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_EN_ES)\n",
    "Bilingual_EN_to_ES_valset = DataLoader(LanguageDataset(val_subset, size_of_val_set_size), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_EN_ES)\n",
    "Bilingual_EN_to_ES_tstset = DataLoader(LanguageDataset(tst_subset, size_of_tst_set_size), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_EN_ES)\n",
    "\n",
    "Bilingual_EN_to_FR_trnset = DataLoader(LanguageDataset(trn_subset, size_of_trn_set_size), batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_EN_FR)\n",
    "Bilingual_EN_to_FR_valset = DataLoader(LanguageDataset(val_subset, size_of_val_set_size), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_EN_FR)\n",
    "Bilingual_EN_to_FR_tstset = DataLoader(LanguageDataset(tst_subset, size_of_tst_set_size), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_EN_FR)\n",
    "\n",
    "Trilingual_trnset = DataLoader(LanguageDataset(trn_subset, size_of_trn_set_size), batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "Trilingual_valset = DataLoader(LanguageDataset(val_subset, size_of_val_set_size), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "Trilingual_tstset = DataLoader(LanguageDataset(tst_subset, size_of_tst_set_size), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "\n",
    "batches_for_training = math.ceil( size_of_trn_set_size / BATCH_SIZE)\n",
    "batches_for_validation = math.ceil( size_of_val_set_size / BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "size_to_MB = 1024 * 1024\n",
    "\n",
    "def getSizeOf(a : torch.Tensor):\n",
    "    return sys.getsizeof(a) + torch.numel(a) * a.element_size()\n",
    "\n",
    "def ElementsOf(a : torch.Tensor):\n",
    "    return torch.numel(a)\n",
    "    \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "total = 0\n",
    "\n",
    "for (src, tgt_ES, tgt_FR) in iter(Trilingual_trnset):\n",
    "\n",
    "    total += getSizeOf(src) / size_to_MB\n",
    "    total += getSizeOf(tgt_ES) / size_to_MB\n",
    "    total += getSizeOf(tgt_FR) / size_to_MB\n",
    "\n",
    "    del src\n",
    "    del tgt_ES\n",
    "    del tgt_FR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Tamaño estimado del conjunto de datos: {} Mbytes\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transformer_model(model : nn.Module):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(label, pred, tgt_pad_idx = PAD_ES_IDX):\n",
    "  pred = torch.argmax(pred, dim=-1)\n",
    "  match = label.eq(pred)\n",
    "  mask = label.ne(tgt_pad_idx)\n",
    "  match = match & mask\n",
    "  match = match.type(torch.float32) \n",
    "  mask =  mask.type(torch.float32)\n",
    "  return torch.sum(match)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def let_gpu_rest(minutes):\n",
    "    if minutes > 0:\n",
    "        time.sleep(minutes * 60)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragmento de código. Funciones que despliegan las curvas de desempeño para el modelo\n",
    "# Se reutilizan a lo largo del ejercicio.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "PLOT_X = 10\n",
    "PLOT_Y = 2.7    \n",
    "\n",
    "def plot_accuracy_curve(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Exactitud del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_acc'], label='Entrenamiento', linestyle='solid', lw=2.5)\n",
    "    ax.plot(history['valid_acc'], label='Validación', linestyle='dashed', lw=2.5)\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_yticks(np.arange(0, 1, 1 / 10))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Exactitud')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_curve(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Pérdida del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_loss'], label='Entrenamiento', linestyle='solid', lw=2.5)\n",
    "    ax.plot(history['valid_loss'], label='Validación', linestyle='dashed', lw=2.5)\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Pérdida')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pplx_curve(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Perplejidad del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_ppl'], label='Entrenamiento', linestyle='solid', lw=2.5)\n",
    "    ax.plot(history['valid_ppl'], label='Validación', linestyle='dashed', lw=2.5)\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Perplejidad')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy_curve_dual_transformer(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Exactitud del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_conjugate_acc'], label='Entrenamiento', linestyle='solid', lw=2.5)\n",
    "    ax.plot(history['valid_conjugate_acc'], label='Validación', linestyle='dashed', lw=2.5)\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_yticks(np.arange(0, 1, 1 / 10))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Exactitud')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss_curve_dual_transformer(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Pérdida del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_conjugate_loss'], label='Entrenamiento', linestyle='solid', lw=2.5)\n",
    "    ax.plot(history['valid_conjugate_loss'], label='Validación', linestyle='dashed', lw=2.5)\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Pérdida')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_curve_dual_transformer_both(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Exactitud del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_acc_a'], label='Entrenamiento (EN-ES)')\n",
    "    ax.plot(history['train_acc_b'], label='Entrenamiento (EN-FR)')\n",
    "    ax.plot(history['valid_acc_a'], label='Validación (EN-ES)')\n",
    "    ax.plot(history['valid_acc_b'], label='Validación (EN-FR)')\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_yticks(np.arange(0, 1, 1 / 10))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Exactitud')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_curve_dual_transformer_both(name, history):\n",
    "    fig, ax = plt.subplots(figsize=(PLOT_X, PLOT_Y), layout='constrained')\n",
    "    ax.set_title('Pérdida del modelo {0}'.format(name))\n",
    "    ax.plot(history['train_loss_a'], label='Entrenamiento (EN-ES)')\n",
    "    ax.plot(history['train_loss_b'], label='Entrenamiento (EN-FR)')\n",
    "    ax.plot(history['valid_loss_a'], label='Validación (EN-ES)')\n",
    "    ax.plot(history['valid_loss_b'], label='Validación (EN-FR)')\n",
    "    ax.set_xticks(np.arange(1, NUMBER_OF_EPOCHS + 1, 1))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Pérdida')\n",
    "    ax.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq-to-Seq using RNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_Learning_Rate = 1e-4\n",
    "\n",
    "ENCODER_EMBEDDING_DIM = 256\n",
    "DECODER_EMBEDDING_DIM = 256\n",
    "ENCODER_HIDDEN_SIZE = 512\n",
    "DECODER_HIDDEN_SIZE = 512\n",
    "\n",
    "encoder_dropout = 0.2 \n",
    "decoder_dropout = 0.2\n",
    "\n",
    "RNN_CLIPPING_VALUE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_EN_ES_model_path = 'RNN_en_es_{0}.pt'\n",
    "RNN_EN_FR_model_path = 'RNN_en_fr_{0}.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/CRCTransformers/deepdive-book/\n",
    "\n",
    "class BahdanauEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout_p):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, encoder_hidden_dim,  bidirectional=True)\n",
    "        self.linear = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        hidden = torch.tanh(self.linear(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/CRCTransformers/deepdive-book/\n",
    "    \n",
    "class BahdanauAttentionQKV(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, query_size=None, key_size=None, dropout_p=0.15):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.query_size = hidden_size if query_size is None else query_size\n",
    "        # assume bidirectional encoder, but can specify otherwise\n",
    "        self.key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        self.query_layer = nn.Linear(self.query_size, hidden_size)\n",
    "        self.key_layer = nn.Linear(self.key_size, hidden_size)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, src_mask=None):\n",
    "        # (B, H)\n",
    "        query_out = self.query_layer(hidden)\n",
    "        # (Src, B, 2*H) --> (Src, B, H)\n",
    "        key_out = self.key_layer(encoder_outputs)\n",
    "        # (B, H) + (Src, B, H) = (Src, B, H)\n",
    "        energy_input = torch.tanh(query_out + key_out)\n",
    "        # (Src, B, H) --> (Src, B, 1) --> (Src, B)\n",
    "        energies = self.energy_layer(energy_input).squeeze(2)\n",
    "        # if a mask is provided, remove masked tokens from softmax calc\n",
    "        if src_mask is not None:\n",
    "            energies.data.masked_fill_(src_mask == 0, float(\"-inf\"))\n",
    "        # softmax over the length dimension\n",
    "        weights = F.softmax(energies, dim=0)\n",
    "        # return as (B, Src) as expected by later multiplication\n",
    "        return weights.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/CRCTransformers/deepdive-book/\n",
    "    \n",
    "class BahdanauDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, attention, dropout_p):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.attention = attention # allowing for custom attention\n",
    "        self.gru = nn.GRU((encoder_hidden_dim * 2) +  embedding_dim, decoder_hidden_dim)\n",
    "        self.out = nn.Linear((encoder_hidden_dim * 2) +  embedding_dim + decoder_hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, src_mask=None):\n",
    "        # (B) --> (1, B)\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attentions = self.attention(hidden, encoder_outputs, src_mask)\n",
    "        # (B, S) --> (B, 1, S)\n",
    "        a = attentions.unsqueeze(1)\n",
    "        # (S, B, 2*Enc) --> (B, S, 2*Enc)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)\n",
    "        # weighted encoder representation\n",
    "        # (B, 1, S) @ (B, S, 2*Enc) = (B, 1, 2*Enc)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        # (B, 1, 2*Enc) --> (1, B, 2*Enc)\n",
    "        weighted = weighted.transpose(0, 1)\n",
    "        # concat (1, B, Emb) and (1, B, 2*Enc)\n",
    "        # results in (1, B, Emb + 2*Enc)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
    "        assert (output == hidden).all()\n",
    "        # get rid of empty leading dimensions\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        # concatenate the pieces above\n",
    "        # (B, Dec), (B, 2*Enc), and (B, Emb)\n",
    "        # result is (B, Dec + 2*Enc + Emb)\n",
    "        linear_input = torch.cat((output, weighted, embedded), dim=1)\n",
    "        # (B, Dec + 2*Enc + Emb) --> (B, O)\n",
    "        output = self.out(linear_input)\n",
    "        return output, hidden.squeeze(0), attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/CRCTransformers/deepdive-book/\n",
    "    \n",
    "class MultipleOptimizer(object):\n",
    "    def __init__(self, optimizers : List):\n",
    "        self.optimizers = optimizers\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for op in self.optimizers:\n",
    "            op.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        for op in self.optimizers:\n",
    "            op.step()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.optimizers[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Encode 1-Decoder Seq2Seq using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/CRCTransformers/deepdive-book/\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, name, encoder, decoder, device=None):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.tgt_vocab_size = decoder.output_dim\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, teacher_forcing_ratio=0.5, return_attentions=False):\n",
    "\n",
    "        tgt_length, batch_size = tgt.shape\n",
    "        \n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        hidden = hidden.squeeze(1) # B, 1, Enc --> B, Enc (if necessary)\n",
    "\n",
    "        \n",
    "        # store decoder outputs\n",
    "        outputs = torch.zeros(tgt_length, batch_size, self.tgt_vocab_size, device=self.device)\n",
    "\n",
    "        # start with  as the decoder input\n",
    "        decoder_input = tgt[0, :]\n",
    "        attentions = []\n",
    "        for t in range(1, tgt_length):\n",
    "            decoder_output, hidden, attention = self.decoder(decoder_input, hidden, encoder_outputs, src_mask)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top_token = decoder_output.max(1)[1]\n",
    "            decoder_input = (tgt[t] if teacher_force else top_token)\n",
    "            attentions.append(attention.unsqueeze(-1))\n",
    "     \n",
    "    \n",
    "        if return_attentions:\n",
    "            return outputs, torch.cat(attentions, dim=-1)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "\n",
    "    def getName(self):\n",
    "        return self.name  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model train and evaluate routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_count = 0\n",
    "\n",
    "def train_single_rnn(model,  dataset, optimizer, loss_fn, src_pad_idx, tgt_pad_idx, device, clip=None, smoothing = True):\n",
    "    model.train()       \n",
    "    epoch_loss = 0\n",
    "    epoch_accm = 0 \n",
    "    epoch_wmem = 0\n",
    "    epoch_lmem = 0   \n",
    "    with tqdm(total=batches_for_training, leave=False) as t:\n",
    "        i = 0\n",
    "        batches_before_gc = 0\n",
    "        for  src, tgt in iter(dataset):\n",
    "           \n",
    "            msk = (src != PAD_ES_IDX)\n",
    "\n",
    "            epoch_wmem += getSizeOf(src)\n",
    "            epoch_wmem += getSizeOf(tgt)\n",
    "            epoch_wmem += getSizeOf(msk)\n",
    "\n",
    "            optimizer.zero_grad()                 \n",
    "\n",
    "            logits =  model(src, tgt, msk, teacher_forcing_ratio=0.5)\n",
    "\n",
    "            loss = 0\n",
    "            accm = 0\n",
    "\n",
    "            epoch_lmem += getSizeOf(logits)\n",
    "\n",
    "            \n",
    "            pv = logits[1:].view(-1, logits.shape[2])\n",
    "            gt = tgt[1:].view(-1)\n",
    "\n",
    "            loss = loss_fn(pv, gt)\n",
    "            loss.backward()\n",
    "        \n",
    "            if (not clip == None):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "            optimizer.step() \n",
    "                \n",
    "            accm = masked_accuracy(gt, pv,  PAD_ES_IDX)\n",
    "        \n",
    "            epoch_loss += loss\n",
    "            epoch_accm += accm\n",
    "             \n",
    "            t.update()\n",
    "            epoch_wmem += getSizeOf(loss)\n",
    "            epoch_wmem += getSizeOf(accm)\n",
    "            i += 1\n",
    "       \n",
    "            del src\n",
    "            del tgt\n",
    "            del msk\n",
    "            del logits\n",
    "            del pv\n",
    "            del gt\n",
    "            del loss\n",
    "            del accm\n",
    "            batches_before_gc += 1\n",
    "    \n",
    "            if (batches_before_gc > gc_count):\n",
    "                torch.cuda.empty_cache()       \n",
    "                batches_before_gc = 0\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    train_loss = (epoch_loss / batches_for_training).item()\n",
    "    train_accm = (epoch_accm / batches_for_training).item() \n",
    "    wrk_mem = epoch_wmem / batches_for_training\n",
    "    log_mem = epoch_lmem / batches_for_training    \n",
    "    return train_loss, train_accm, wrk_mem, log_mem\n",
    "    \n",
    "def eval_single_rnn(model,  dataset, loss_fn, src_pad_idx, tgt_pad_idx, device):\n",
    "    model.eval()    \n",
    "    epoch_loss = 0\n",
    "    epoch_accm = 0 \n",
    "    epoch_wmem = 0\n",
    "    epoch_lmem = 0  \n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=batches_for_validation, leave=False) as t:       \n",
    "            i = 0\n",
    "            batches_before_gc = 0\n",
    "            for  src, tgt in iter(dataset):\n",
    "\n",
    "                msk = (src != PAD_ES_IDX)\n",
    "\n",
    "                epoch_wmem += getSizeOf(src)\n",
    "                epoch_wmem += getSizeOf(tgt)\n",
    "                epoch_wmem += getSizeOf(msk)\n",
    "            \n",
    "                logits =  model(src, tgt, msk,  teacher_forcing_ratio=0.0)\n",
    "\n",
    "                loss = 0\n",
    "                accm = 0\n",
    "\n",
    "                epoch_lmem += getSizeOf(logits)\n",
    "\n",
    "                pv = logits[1:].view(-1, logits.shape[2])\n",
    "                gt = tgt[1:].view(-1)\n",
    "\n",
    "                loss = loss_fn(pv, gt)\n",
    "                accm = masked_accuracy(gt, pv,  PAD_ES_IDX)\n",
    "\n",
    "                epoch_loss += loss              \n",
    "                epoch_accm += accm\n",
    "\n",
    "\n",
    "                epoch_wmem += getSizeOf(loss)\n",
    "                epoch_wmem += getSizeOf(accm)\n",
    "                t.update()\n",
    "                i += 1\n",
    " \n",
    "                del src\n",
    "                del tgt\n",
    "                del msk\n",
    "                del logits\n",
    "                del pv\n",
    "                del gt\n",
    "                del loss\n",
    "                del accm\n",
    "                batches_before_gc += 1\n",
    "                if (batches_before_gc > gc_count):\n",
    "                    torch.cuda.empty_cache()       \n",
    "                    batches_before_gc = 0\n",
    "                if i > 5:\n",
    "                    break\n",
    "    \n",
    "    valid_loss = (epoch_loss / batches_for_validation).item()\n",
    "    valid_accm = (epoch_accm / batches_for_validation).item()\n",
    "    wrk_mem = epoch_wmem / batches_for_validation\n",
    "    log_mem = epoch_lmem / batches_for_validation\n",
    "    return valid_loss , valid_accm, wrk_mem, log_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def run_single_rnn(model, filename, trnset, valset, optimizer, loss_fn, src_pad_idx, tgt_pad_idx):\n",
    "    \n",
    "    \n",
    "    print(model.getName())    \n",
    "    \n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "\n",
    "\n",
    "    metrics_by_epoch = {}\n",
    "    \n",
    "    best_valid_loss = float(\"inf\")\n",
    "    \n",
    "    early_stopping_count = 0\n",
    "\n",
    "    base_epoch = -1 \n",
    "    # Check for previos training checkpoints (latest)\n",
    "    for epoch in range(NUMBER_OF_EPOCHS):\n",
    "        if os.path.exists(filename.format(epoch)):\n",
    "            base_epoch = epoch\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Load the latest checkpoint \n",
    "    if (base_epoch >= 0):\n",
    "        # Load model checkpoint file (latest)\n",
    "        checkpoint = torch.load(filename.format(base_epoch))\n",
    "        # Load model data only when match filename with epoch information\n",
    "        if (checkpoint['epoch'] == base_epoch):\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer[0].load_state_dict(checkpoint['optimizer_enc_state_dict'])\n",
    "            optimizer[1].load_state_dict(checkpoint['optimizer_dec_state_dict'])\n",
    "            metrics_by_epoch = checkpoint['metrics_by_epoch']\n",
    "            best_valid_loss = checkpoint['best_valid_loss']\n",
    "            early_stopping_count = checkpoint['early_stopping_count']\n",
    "            print(\"Continuing training model {0} from checkpoint at epoch {1}\".format(model.getName(), base_epoch + 1))\n",
    "        else:\n",
    "            raise RuntimeError(\"Checkpoint {0} is corrupt\".format(base_epoch))\n",
    "\n",
    "    if (base_epoch + 1 < NUMBER_OF_EPOCHS):\n",
    "        for epoch in tqdm(range(base_epoch + 1, NUMBER_OF_EPOCHS), desc=\"Epoch\"):\n",
    "\n",
    "            \n",
    "\n",
    "            start_time = timer()      \n",
    "            train_loss, train_acc, trn_wrk_mem, trn_log_mem = train_single_rnn(model, trnset, optimizer, loss_fn,  src_pad_idx, tgt_pad_idx, DEVICE, clip=CLIPPING_VALUE)\n",
    "            end_time = timer()\n",
    "           \n",
    "               \n",
    "            valid_loss, valid_acc, val_wrk_mem, val_log_mem = eval_single_rnn(model, valset, loss_fn, src_pad_idx, tgt_pad_idx, DEVICE)\n",
    "            seconds = end_time - start_time\n",
    "\n",
    "            tqdm.write(\"Model {0} at Epoch {1} Trn.Loss = {2} and Trn.Accuracy = {3}\".format(model.getName(), epoch + 1, train_loss, train_acc))\n",
    "            tqdm.write(\"Model {0} at Epoch {1} Val.Loss = {2} and Val.Accuracy = {3}\".format(model.getName(), epoch + 1, valid_loss, valid_acc))\n",
    "\n",
    "            metrics_by_epoch[epoch + 1] = dict(\n",
    "                model_name = model.getName(),\n",
    "                model_epoch = epoch + 1,\n",
    "                train_loss = train_loss,\n",
    "                train_acc = train_acc,\n",
    "                train_ppl = np.exp(train_loss),\n",
    "                train_wrkmem = trn_wrk_mem,\n",
    "                train_logmem = trn_log_mem,\n",
    "                valid_loss = valid_loss,\n",
    "                valid_acc = valid_acc,\n",
    "                valid_ppl = np.exp(valid_loss),\n",
    "                valid_wrkmem = val_wrk_mem,\n",
    "                valid_logmem = val_log_mem,\n",
    "                time = seconds\n",
    "            )\n",
    "\n",
    "\n",
    "            temp_filename = \"temp_\" + filename.format(epoch)\n",
    "\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_enc_state_dict': optimizer[0].state_dict(),\n",
    "            'optimizer_dec_state_dict': optimizer[1].state_dict(),\n",
    "            'early_stopping_count': early_stopping_count,\n",
    "            'metrics_by_epoch' : metrics_by_epoch,\n",
    "            'best_valid_loss' : best_valid_loss\n",
    "            }, temp_filename)\n",
    "\n",
    "            os.rename(temp_filename, filename.format(epoch))\n",
    "\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                early_stopping_count = 0\n",
    "            elif epoch > EARLY_STOPPING_EPOCHS:\n",
    "                early_stopping_count += 1\n",
    "                      \n",
    "            if early_stopping_count == EARLY_STOPPING_EPOCHS:\n",
    "                tqdm.write(f\"Early stopping triggered in epoch {epoch + 1}\")\n",
    "                break\n",
    "        \n",
    "            tqdm.write(\"Waiting for gpu cooling time...\")\n",
    "\n",
    "            let_gpu_rest(INNER_GPU_REST_TIME)\n",
    "\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = SortKey.CUMULATIVE\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats()\n",
    "    print(s.getvalue())\n",
    "\n",
    "\n",
    "    return metrics_by_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc_ES = BahdanauEncoder(input_dim=en_vocab_size, embedding_dim=ENCODER_EMBEDDING_DIM, encoder_hidden_dim=ENCODER_HIDDEN_SIZE, decoder_hidden_dim=DECODER_HIDDEN_SIZE, dropout_p = encoder_dropout)\n",
    "enc_FR = BahdanauEncoder(input_dim=en_vocab_size, embedding_dim=ENCODER_EMBEDDING_DIM, encoder_hidden_dim=ENCODER_HIDDEN_SIZE, decoder_hidden_dim=DECODER_HIDDEN_SIZE, dropout_p = encoder_dropout)\n",
    "\n",
    "attn_ES = BahdanauAttentionQKV(DECODER_HIDDEN_SIZE)\n",
    "attn_FR = BahdanauAttentionQKV(DECODER_HIDDEN_SIZE)\n",
    "\n",
    "dec_ES = BahdanauDecoder(output_dim=es_vocab_size, embedding_dim=DECODER_EMBEDDING_DIM, encoder_hidden_dim=ENCODER_HIDDEN_SIZE, decoder_hidden_dim=DECODER_HIDDEN_SIZE, attention=attn_ES, dropout_p=decoder_dropout)\n",
    "dec_FR = BahdanauDecoder(output_dim=fr_vocab_size, embedding_dim=DECODER_EMBEDDING_DIM, encoder_hidden_dim=ENCODER_HIDDEN_SIZE, decoder_hidden_dim=DECODER_HIDDEN_SIZE, attention=attn_FR, dropout_p=decoder_dropout)\n",
    "\n",
    "seq2seq_EN_ES = Seq2Seq(\"RNN_EN_ES\", enc_ES, dec_ES, DEVICE)\n",
    "seq2seq_EN_FR = Seq2Seq(\"RNN_EN_FR\", enc_FR, dec_FR, DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "RNN_enc_optim_EN_ES = torch.optim.AdamW(seq2seq_EN_ES.encoder.parameters(),lr=RNN_Learning_Rate)\n",
    "RNN_dec_optim_EN_ES = torch.optim.AdamW(seq2seq_EN_ES.decoder.parameters(),lr=RNN_Learning_Rate)\n",
    "\n",
    "RNN_enc_optim_EN_FR = torch.optim.AdamW(seq2seq_EN_FR.decoder.parameters(),lr=RNN_Learning_Rate)\n",
    "RNN_dec_optim_EN_FR = torch.optim.AdamW(seq2seq_EN_FR.decoder.parameters(),lr=RNN_Learning_Rate)\n",
    "\n",
    "loss_fn_RNN_EN_ES = torch.nn.CrossEntropyLoss(ignore_index=PAD_ES_IDX)\n",
    "loss_fn_RNN_EN_FR = torch.nn.CrossEntropyLoss(ignore_index=PAD_FR_IDX)\n",
    "\n",
    "optims_EN_ES = MultipleOptimizer([RNN_enc_optim_EN_ES, RNN_dec_optim_EN_ES])\n",
    "optims_EN_FR = MultipleOptimizer([RNN_enc_optim_EN_FR, RNN_dec_optim_EN_FR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "seq2seq_EN_ES.apply(init_transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_params(seq2seq_EN_ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "seq2seq_EN_FR.apply(init_transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_params(seq2seq_EN_FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histories = []\n",
    "\n",
    "\n",
    "import cProfile, pstats, io\n",
    "\n",
    "\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "seq2seq_EN_ES = seq2seq_EN_ES.to(DEVICE)\n",
    "history = run_single_rnn(seq2seq_EN_ES, RNN_EN_ES_model_path, Bilingual_EN_to_ES_trnset, Bilingual_EN_to_ES_valset, optims_EN_ES, loss_fn_RNN_EN_ES, PAD_EN_IDX, PAD_ES_IDX)\n",
    "name = seq2seq_EN_ES.getName()\n",
    "df = pd.DataFrame.from_dict(history, orient='index')   \n",
    "plot_accuracy_curve(name, df)\n",
    "plot_loss_curve(name, df)\n",
    "plot_pplx_curve(name, df)\n",
    "histories.append(df)\n",
    "torch.cuda.empty_cache()\n",
    "let_gpu_rest(OUTER_GPU_REST_TIME)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "seq2seq_EN_FR = seq2seq_EN_FR.to(DEVICE)\n",
    "history = run_single_rnn(seq2seq_EN_FR, RNN_EN_FR_model_path, Bilingual_EN_to_FR_trnset, Bilingual_EN_to_FR_valset, optims_EN_FR, loss_fn_RNN_EN_FR, PAD_EN_IDX, PAD_FR_IDX)\n",
    "name = seq2seq_EN_FR.getName()\n",
    "df = pd.DataFrame.from_dict(history, orient='index')   \n",
    "plot_accuracy_curve(name, df)\n",
    "plot_loss_curve(name, df)\n",
    "plot_pplx_curve(name, df)\n",
    "histories.append(df)\n",
    "torch.cuda.empty_cache()\n",
    "let_gpu_rest(OUTER_GPU_REST_TIME)\n",
    "\n",
    "\n",
    "result = pd.concat(histories)\n",
    "result.to_csv(\"./metrics_of_rnn_models.csv\", sep=';', index=True, encoding='utf-8')\n",
    "\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
